{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has lots of very unpolished code that was used to visualize results. Proceed with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_max_displacement_in_folder(folder):\n",
    "    files = os.listdir(folder)\n",
    "    maxes = []\n",
    "    bad_idx = []\n",
    "    for i, file in enumerate(files):\n",
    "        name = os.path.join(folder, file)\n",
    "        data = np.load(name)\n",
    "        maxval = np.max(np.abs(data[\"disp\"][:,2]))\n",
    "        maxes.append(maxval)\n",
    "        print(i, end=\"\\r\")\n",
    "        if maxval > 0.5:\n",
    "            bad_idx.append(i)\n",
    "    maxes = np.array(maxes)\n",
    "    return maxes, bad_idx\n",
    "    \n",
    "maxes, bad = get_max_displacement_in_folder(\"../data-train\")\n",
    "maxes_te, bad_te = get_max_displacement_in_folder(\"../data-test\")\n",
    "maxes_val, bad_val = get_max_displacement_in_folder(\"../data-val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import importlib\n",
    "from models_gpu import * # Modified\n",
    "from coarsen import *\n",
    "import torch\n",
    "import torch.optim as opt\n",
    "from visualize import *\n",
    "from evaluate import *\n",
    "from load_graphs import *\n",
    "from visualize import *\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NetFabbDataset(\"../data-train\", npz_mode=True, N=4, factor=8)\n",
    "test_dataset = NetFabbDataset(\"../data-test\", npz_mode=True, N=4, factor=8)\n",
    "val_dataset = NetFabbDataset(\"../data-val\", npz_mode=True, N=4, factor=8)\n",
    "\n",
    "\n",
    "bad_names = [train_dataset.files[i] for i in bad]\n",
    "bad_names_te = [test_dataset.files[i] for i in bad_te]\n",
    "bad_names_val = [val_dataset.files[i] for i in bad_val]\n",
    "\n",
    "for name in bad_names:\n",
    "    train_dataset.files.remove(name)\n",
    "for name in bad_names_te:\n",
    "    test_dataset.files.remove(name)\n",
    "for name in bad_names_val:\n",
    "    val_dataset.files.remove(name)\n",
    "\n",
    "train_loader = NetFabbDataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "test_loader = NetFabbDataLoader(train_dataset, shuffle=True)\n",
    "val_loader = NetFabbDataLoader(val_dataset, shuffle=True)\n",
    "\n",
    "datasets = dict(tr=train_dataset, te=test_dataset) #, val=val_dataset)\n",
    "model_names = [\"model-gcn-unet\",\"model-gnn-600k-f8-50-v2\",\"model-600k-f8-75\"] # \"gnn-30-epoch\",\"model-50-epoch\",\"model-big-75\",\"model-300k-50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_scores_to_file(vals, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        for key in vals:\n",
    "            f.write(f\"{key}\\n\")\n",
    "            f.write(f\"{len(vals[key])}\\n\")\n",
    "            for val in vals[key]:\n",
    "                f.write(f\"{val}\\n\")\n",
    "\n",
    "def read_scores_from_file(path):\n",
    "    vals = dict()\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        key = lines[i][:-1]\n",
    "        i += 1\n",
    "        count = int(lines[i])\n",
    "        vals[key] = np.zeros(count)\n",
    "        i += 1\n",
    "        for j in range(count):\n",
    "            vals[key][j] = float(lines[i])\n",
    "            i += 1\n",
    "    return vals\n",
    "\n",
    "\n",
    "def sort_scores(vals):\n",
    "    idx = dict()\n",
    "    for key in vals:\n",
    "        idx[key] = np.argsort(vals[key])\n",
    "    return idx\n",
    "    \n",
    "\n",
    "def get_and_save_scores(model_filename):\n",
    "    model = torch.load(\"../\"+model_filename+\".pth\", map_location=\"cpu\").to(device)\n",
    "    scores = eval_model_multiple(model, datasets, device)\n",
    "    export_scores_to_file(scores, \"../results/results_\"+model_filename+\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\"unet-2\", \"unet-4\"]\n",
    "# for name in model_names:\n",
    "#     print(f\"Starting for {name}\")\n",
    "#     get_and_save_scores(name)\n",
    "\n",
    "#get_and_save_scores(\"model-gcn-unet\")\n",
    "get_and_save_scores(\"unet-1\")\n",
    "# get_and_save_scores(\"unet-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\"unet-1\",\"unet-2\", \"unet-3\", \"unet-4\"]\n",
    "model_names = [\"model-gnn-600k-f8-50-v2\", \"model-gcn-unet\", \"unet-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = dict()\n",
    "scores_idx = dict()\n",
    "models = dict()\n",
    "for name in model_names:\n",
    "    scores = read_scores_from_file(\"../results/results_\"+name+\".txt\")\n",
    "    scores_idx[name] = sort_scores(scores)\n",
    "    scores_list[name] = scores\n",
    "    models[name] = torch.load(\"../\"+name+\".pth\", map_location=\"cpu\").to(device)\n",
    "\n",
    "get_best = lambda name, offset: scores_idx[name][\"te\"][-1-offset]\n",
    "get_worst = lambda name, offset: scores_idx[name][\"te\"][0+offset]\n",
    "get_median = lambda name, offset: scores_idx[name][\"te\"][len(datasets[\"te\"])//2 + offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_vis(model_name, get = \"best\", offset = 0):\n",
    "    model = models[model_name]\n",
    "    if get == \"best\":\n",
    "        get_fn = get_best\n",
    "    elif get == \"worst\":\n",
    "        get_fn = get_worst\n",
    "    elif get == \"median\":\n",
    "        get_fn = get_median\n",
    "\n",
    "    i = get_fn(model_name, offset)\n",
    "\n",
    "    data = test_dataset[i]\n",
    "\n",
    "\n",
    "    verts = data.x.detach().numpy()\n",
    "    gt = data.y.detach().numpy()\n",
    "    pred = model(data, device).cpu().detach().numpy()\n",
    "\n",
    "    thres=0.02\n",
    "\n",
    "    print(f\"{model_name}, {get}, {offset}\")\n",
    "    print(f\"{datasets['te'].files[i][:-4]}\")\n",
    "    print(f\"R2 = {scores_list[model_name]['te'][i]:.3f}\")\n",
    "    print(f\"Accuracy = {100*accuracy_score(gt>thres, pred>thres):.1f}%\")\n",
    "    print(f\"F1 Score = {f1_score(gt>thres, pred>thres):.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plot_fields_custom(verts,[gt, pred,gt>thres,pred>thres], [\"Ground Truth\", \"Prediction\",f\"G.T. > {thres}\", f\"Pred. > {thres}\"], cmaps = [\"jet\", \"jet\", \"bluered\", \"bluered\"], limgroups = [0,0,1,1]) \n",
    "    return datasets['te'].files[i][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"unet-3\"\n",
    "print(name)\n",
    "get_vis(name, \"median\", -47) #-47\n",
    "get_vis(name, \"median\", 96) #101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in model_names:\n",
    "    get_vis(name, \"best\", 0)\n",
    "    get_vis(name, \"median\", 1)\n",
    "    get_vis(name, \"worst\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.array(scores_list[\"model-600k-f8-75\"][\"te\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = \"model-600k-f8-75\"\n",
    "for name in model_names:\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Train: {np.median(np.array(scores_list[name]['tr'])):.3f}\")\n",
    "    print(f\"Test: {np.median(np.array(scores_list[name]['te'])):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = dict()\n",
    "model_str[\"model-gcn-unet\"] = \"TAG U-Net (GCNConv)\"\n",
    "model_str[\"unet-3\"] = \"TAG U-Net (EdgeConv)\"\n",
    "model_str[\"model-gnn-600k-f8-50-v2\"] = \"Plain GNN (EdgeConv)\"\n",
    "\n",
    "model_color=dict()\n",
    "model_color[\"model-gcn-unet\"] = \"blue\"\n",
    "model_color[\"unet-3\"] = \"darkgreen\"\n",
    "model_color[\"model-gnn-600k-f8-50-v2\"] = \"darkred\"\n",
    "\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "\n",
    "for model in model_names:\n",
    "    te = scores_list[model][\"te\"]\n",
    "    log=True\n",
    "    plt.hist(te[te>-1], bins=40, density=True, histtype=\"step\", lw=3., edgecolor=model_color[model], label=model_str[model])\n",
    "    #plt.hist(te[te>-1], bins=50, density=True, alpha=0.3, log=log, histtype=\"stepfilled\", color=model_color[model])\n",
    "plt.legend()\n",
    "plt.xlabel(\"$R^2$\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"3-D Displacement Prediction Task\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fields(xyz, fields, titles = None, cmap=\"coolwarm\"):\n",
    "    if titles is not None:\n",
    "        assert len(fields) == len(titles)\n",
    "    N = len(fields)\n",
    "\n",
    "    vmin = min([min(f) for f in fields])\n",
    "    vmax = max([max(f) for f in fields])\n",
    "\n",
    "    fig = plt.figure(figsize=(3.5*N,4),dpi=300)\n",
    "    for i, field in enumerate(fields):\n",
    "        ax = fig.add_subplot(1, N, i+1, projection='3d')\n",
    "        ax.scatter(xyz[:,0],xyz[:,1],xyz[:,2],c=field, cmap=cmap, vmin = vmin, vmax = vmax)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "        equal_axes(ax)\n",
    "        plt.title(titles[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_r2(model, data, lims=None, size=1, device=\"cpu\"):\n",
    "    pred = model(data, device).cpu().detach().numpy().flatten()\n",
    "    gt = data.y.detach().numpy().flatten()\n",
    "    plot_r2(gt, pred, lims=lims, size=size)\n",
    "\n",
    "def plot_model_comparison(models, data, model_names, filename=None, dpi=300, size=13, device=\"cpu\"):\n",
    "    N = len(models)\n",
    "    fig = plt.figure(figsize=(4.3*(N+1), 9.05), dpi=dpi)\n",
    "    s = size# / (1 + 7*(3000<data.x.shape[0]))\n",
    "    small_axes = []\n",
    "\n",
    "    preds = dict()\n",
    "\n",
    "    vmin = min(data.y.detach().numpy().flatten())\n",
    "    vmax = max(data.y.detach().numpy().flatten())\n",
    "\n",
    "    preds[\"gt\"] = data.y.detach().numpy().flatten()\n",
    "    model_names[\"gt\"] = \"Ground Truth\"\n",
    "\n",
    "    for key in models:\n",
    "        model = models[key].to(device)\n",
    "        pred = model(data, device=device).cpu().detach().numpy().flatten()\n",
    "        preds[key] = pred\n",
    "        vmin = min(vmin, min(pred))\n",
    "        vmax = max(vmax, max(pred))\n",
    "\n",
    "    \n",
    "\n",
    "    xyz = data.x.detach().numpy()\n",
    "    cmap = \"jet\"\n",
    "    \n",
    "    print(N+1)\n",
    "    i = 0\n",
    "    for key in preds:\n",
    "        ax = fig.add_subplot(2, N+1, i+1, projection='3d')\n",
    "        handle = ax.scatter(xyz[:,0],xyz[:,1],xyz[:,2],c=preds[key], cmap=cmap, vmin = vmin, vmax = vmax)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "        equal_axes(ax)\n",
    "        plt.title(model_names[key], fontsize=14)\n",
    "\n",
    "        colorbar=True\n",
    "        if colorbar:\n",
    "            cbar_shrink = 0.93\n",
    "            cbar_pad = -0.02\n",
    "            ticks=[vmin, np.round((vmin + vmax)/2,3), vmax]\n",
    "            bar = plt.colorbar(handle, shrink=cbar_shrink, location='bottom', pad=cbar_pad, ticks=ticks)\n",
    "            bar.ax.set_xticklabels([np.round(vmin,3), np.round((vmin + vmax)/2,3), np.round(vmax,3)])\n",
    "\n",
    "        if key != \"gt\":\n",
    "            ax = plt.subplot(2,N+1,i+N+2)\n",
    "            plot_r2(preds[\"gt\"], preds[key])\n",
    "            plt.ylabel(\"Prediction\")\n",
    "            plt.axis(\"scaled\")\n",
    "            small_axes.append(ax)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.14, hspace=0)\n",
    "    for ax in small_axes:\n",
    "        pos1 = ax.get_position() # get the original position \n",
    "        pos2 = [pos1.x0 + 0.02, pos1.y0 + 0.1/N,  pos1.width * 0.8, pos1.height * 0.8] \n",
    "        ax.set_position(pos2) # set a new position\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, bbox_inches = \"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    data = datasets['te'][i]\n",
    "    print(datasets['te'].files[i][:-4])\n",
    "    fig = plt.figure(dpi=200)\n",
    "    xyz = data.x\n",
    "    field = data.y\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xyz[:,0],xyz[:,1],xyz[:,2],c=field, cmap=\"jet\")\n",
    "    equal_axes(ax)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(scores_list['unet-3']['te'])\n",
    "imed = idx[len(idx)//2]\n",
    "data = datasets['te'][imed]\n",
    "print(datasets['te'].files[imed])\n",
    "\n",
    "plot_model_comparison(models,data, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "tr = scores_list[\"unet-3\"][\"tr\"]\n",
    "te = scores_list[\"unet-3\"][\"te\"]\n",
    "plt.hist(tr[tr>0], bins=100, density=True, label=\"Train\")\n",
    "plt.hist(te[te>0], bins=100, density=True, alpha=.5, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$R^2$\")\n",
    "plt.ylabel(\"Percent of shapes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "tr = scores_list[\"unet-3\"][\"tr\"]\n",
    "te = scores_list[\"unet-3\"][\"te\"]\n",
    "plt.hist(tr[tr>0], bins=100, density=True, label=\"Train\")\n",
    "plt.hist(te[te>0], bins=100, density=True, alpha=.5, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$R^2$\")\n",
    "plt.ylabel(\"Percent of shapes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violins(scores_list[\"unet-3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxes(scores_list[\"unet-3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "def get_rot_fn(w):\n",
    "    Rs = torch.tensor([\n",
    "         [[1,0,0],[0,1,0],[0,0,1]],\n",
    "         [[1,0,0],[0,0,1],[0,-1,0]],\n",
    "         [[0,0,1],[0,1,0],[-1,0,0]],\n",
    "         [[1,0,0],[0,-1,0],[0,0,1]],\n",
    "         [[1,0,0],[0,0,-1],[0,1,0]],\n",
    "         [[0,0,-1],[0,1,0],[1,0,0]]], dtype=torch.float)\n",
    "    R = Rs[w]\n",
    "    def rotate(X):\n",
    "        X = X @ R\n",
    "        # Minimum z-value should be 0\n",
    "        # x and y bounds should be centered at 0\n",
    "        X[:,2] = X[:,2] - torch.min(X[:,2])\n",
    "        medx = (torch.max(X[:,0])-torch.min(X[:,0]))/2.\n",
    "        medy = (torch.max(X[:,1])-torch.min(X[:,1]))/2.\n",
    "        X[:,0] = X[:,0] - medx\n",
    "        X[:,1] = X[:,1] - medy\n",
    "        return X\n",
    "    return rotate\n",
    "\n",
    "\n",
    "def rotate_shape(data, w):\n",
    "    rotate = get_rot_fn(w)\n",
    "    new = Data(x=rotate(data.x), y=data.y, edge_index=data.edge_index)\n",
    "    return Coarsen(new, factor=data.factor, N=data.N)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_all_orientations(data, model, cmap=\"jet\", title=\"\"):\n",
    "    fig = plt.figure(figsize=(12,6),dpi=200)\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    peaks = []\n",
    "    for i in range(6):\n",
    "        d = rotate_shape(data,i)\n",
    "        mins.append(np.min(model(d, device).cpu().detach().numpy()))\n",
    "        maxs.append(np.max(model(d, device).cpu().detach().numpy()))\n",
    "        peaks.append(max([maxs[i], abs(mins[i])]))\n",
    "\n",
    "    min_index = np.argmin(np.array(peaks))\n",
    "    max_index = np.argmax(np.array(peaks))\n",
    "\n",
    "    for i in range(6):\n",
    "        ax = fig.add_subplot(2,3,i+1, projection='3d')\n",
    "        d = rotate_shape(data,i)\n",
    "        xyz = d.x.cpu().detach().numpy()\n",
    "        scatter = ax.scatter(xyz[:,0],xyz[:,1],xyz[:,2],c=model(d, device).cpu().detach().numpy(), \n",
    "                             cmap=cmap, vmin=min(mins), vmax=max(maxs))\n",
    "        #cbar = fig.colorbar(scatter, format=\"% .2f\", shrink=0.8)\n",
    "        if i == min_index:\n",
    "            plt.title(f\"BEST: Peak = {peaks[i]:.2f}\")\n",
    "        elif i == max_index:\n",
    "            plt.title(f\"WORST: Peak = {peaks[i]:.2f}\")\n",
    "        else:\n",
    "            plt.title(f\"Peak = {peaks[i]:.2f}\")\n",
    "\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "data = datasets[\"te\"][i]\n",
    "\n",
    "plot_all_orientations(data,models[model_names[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_scores(model, dataset, threshold = 0.02, device=\"cpu\"):\n",
    "    py_gy = 0\n",
    "    py_gn = 0\n",
    "    pn_gy = 0\n",
    "    pn_gn = 0\n",
    "    accs = []\n",
    "    f1s = []\n",
    "\n",
    "    for data in dataset:\n",
    "        gt = data.y.cpu().detach().numpy().flatten()\n",
    "        pred = model(data, device).cpu().detach().numpy().flatten()\n",
    "\n",
    "        gt_bin = gt > threshold\n",
    "        pred_bin = pred > threshold\n",
    "\n",
    "        accs.append(accuracy_score(gt_bin, pred_bin))\n",
    "        f1s.append(f1_score(gt_bin, pred_bin,))\n",
    "        py_gy += np.sum(np.logical_and(gt_bin, pred_bin))\n",
    "        py_gn += np.sum(np.logical_and(gt_bin, np.logical_not(pred_bin)))\n",
    "        pn_gy += np.sum(np.logical_and( np.logical_not(gt_bin), pred_bin))\n",
    "        pn_gn += np.sum(np.logical_and(np.logical_not(gt_bin),  np.logical_not(pred_bin)))\n",
    "\n",
    "    results = dict(py_gy=py_gy, py_gn=py_gn, pn_gn=pn_gn, pn_gy=pn_gy, accs=np.array(accs), f1s=np.array(f1s))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_te\n",
    "print(\"median\",np.median(results[\"accs\"]))\n",
    "print(\"mean\",np.mean(results[\"accs\"]))\n",
    "print(\"stdev\",np.std(results[\"accs\"]))\n",
    "\n",
    "print(\"median\",np.median(results[\"f1s\"]))\n",
    "print(\"mean\",np.mean(results[\"f1s\"]))\n",
    "print(\"stdev\",np.std(results[\"f1s\"]))\n",
    "\n",
    "print(\"                 GT <= 0.02,     GT > 0.02\")\n",
    "print(f\"Pred <= 0.02:     {results['pn_gn']},   {results['pn_gy']}\")\n",
    "print(f\"Pred > 0.02:     {results['py_gn']},   {results['py_gy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_te = get_acc_scores(models[\"unet-3\"], datasets[\"te\"])\n",
    "print(\"1 done.\")\n",
    "results_tr = get_acc_scores(models[\"unet-3\"], datasets[\"tr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def auto_crop(image_file):\n",
    "    \n",
    "    image = Image.open(image_file)\n",
    "    A = np.array(image)\n",
    "\n",
    "    rows = A.shape[0]\n",
    "    cols = A.shape[1]\n",
    "\n",
    "    for i in range(cols):\n",
    "        if len(np.unique(A[:,i])) > 1:\n",
    "            A = A[:,i:]\n",
    "            cols = A.shape[1]\n",
    "            break\n",
    "\n",
    "    for i in range(cols-1,0,-1):\n",
    "        if len(np.unique(A[:,i])) > 1:\n",
    "            A = A[:,:i]\n",
    "            rows = A.shape[0]\n",
    "            break\n",
    "\n",
    "    for i in range(rows):\n",
    "        if len(np.unique(A[i,:])) > 1:\n",
    "            A = A[i:,:]\n",
    "            rows = A.shape[0]\n",
    "            break\n",
    "\n",
    "    for i in range(rows-1,0,-1):\n",
    "        if len(np.unique(A[i,:])) > 1:\n",
    "            A = A[:i,:]\n",
    "            break\n",
    "\n",
    "    image = Image.fromarray(A)\n",
    "\n",
    "    # Save the image\n",
    "    image.save(image_file) \n",
    "\n",
    "\n",
    "def plot_index(i):\n",
    "    data = datasets['te'][i]\n",
    "    print(datasets['te'].files[i][:-4])\n",
    "    fig = plt.figure(dpi=300)\n",
    "    xyz = data.x\n",
    "    field = data.y\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xyz[:,0],xyz[:,1],xyz[:,2],c=field, cmap=\"jet\")\n",
    "    equal_axes(ax)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"temp.png\")\n",
    "    plt.close()\n",
    "    auto_crop(\"temp.png\")\n",
    "    img = Image.open(\"temp.png\")\n",
    "    #plt.figure(dpi=300)\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return datasets['te'].files[i][:-4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(20):\n",
    "    names.append(plot_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(scores_list['unet-3']['te'])\n",
    "imed = idx[3*len(idx)//4-1]\n",
    "i = imed\n",
    "data = datasets['te'][i]\n",
    "print(datasets['te'].files[i])\n",
    "\n",
    "plot_model_comparison(models,data, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-360-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
