{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from coarsen import *\n",
    "from scipy import io\n",
    "from torch_geometric.transforms import FaceToEdge\n",
    "from models_gpu import *\n",
    "from visualize import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_graph(mat,index):\n",
    "    '''\n",
    "    get_graph: Reads a single data point from already-loaded matlab data\n",
    "    \n",
    "    mat - The dictionary of values read from a .mat file\n",
    "    index - The index of the data point\n",
    "    \n",
    "    Returns - The Data() representation of 'mat'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    nodes = mat['nodes'][index,0].T\n",
    "    elems = mat['elem'][index,0].T-1\n",
    "    stress = mat['stress'][index,0]\n",
    "    dt = mat['dt'][index,0]\n",
    "    sdf = mat['sdf'][index][0].T\n",
    "\n",
    "    f2e = FaceToEdge(remove_faces=True)\n",
    "\n",
    "    x = torch.tensor(np.concatenate((nodes,dt), axis=1), dtype=torch.float)\n",
    "    y = torch.tensor(stress, dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, face = torch.tensor(elems.T), y=y)\n",
    "    data = f2e(data)\n",
    "    data.sdf = torch.tensor(sdf, dtype=torch.float)\n",
    "    return data\n",
    "\n",
    "def load_matlab_dataset(filename, scale = 10000):\n",
    "    '''\n",
    "    load_matlab_dataset: Loads a scalar field dataset from a .mat file  \n",
    "    \n",
    "    Inputs:\n",
    "    - filename - The .mat dataset consisting of meshes, the scalar field and SDF at each node, and an SDF array\n",
    "    - scale - The number to divide each scalar field value by, defaults to 10000   \n",
    "    \n",
    "    Returns:\n",
    "    - The dataset as a list of Data() objects\n",
    "    \n",
    "    '''\n",
    "    mat = io.loadmat(filename)\n",
    "    dataset = []\n",
    "    for i in range(len(mat['nodes'])):\n",
    "        data = get_graph(mat, i)\n",
    "        data.y /= scale\n",
    "        data.sdf = data.sdf[None, None, :, :] * 10\n",
    "        dataset.append(data)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "\n",
    "class StressDataset(Dataset):\n",
    "    def __init__(self, zipfiles, **kwargs):\n",
    "        self.zipfiles = zipfiles\n",
    "        self.options = kwargs\n",
    "        self.data = []\n",
    "        for zipfile in zipfiles:\n",
    "            self.data += load_matlab_dataset(zipfile)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = coarsen_data(self.data[idx], **self.options)\n",
    "        return X\n",
    "    \n",
    "def split_dataset(dataset, train_frac=0.8, seed=216):\n",
    "    train_size = int(0.8*len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator)\n",
    "    print(f\"Splitting dataset with seed {seed}: {train_size} training, {test_size} testing\")\n",
    "    return train_dataset, test_dataset\n",
    "    \n",
    "class StressDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        super().__init__(dataset, collate_fn=merge_coarsened_data, dimension=2, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StressDataset([\"data/stress_vor_w.mat\", \"data/stress_lat_w.mat\"])\n",
    "dataset_tr, dataset_te = split_dataset(dataset)\n",
    "train_loader = StressDataLoader(dataset_tr, batch_size=4)\n",
    "test_loader = StressDataLoader(dataset_te, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "conv_info = get_default_conv_info(\"GCNConv\")\n",
    "model = GraphUNet(num_layers=3, num_channels=64, conv_info=conv_info, mlp_dims=[128,128,128]).to(device)\n",
    "# 64 minutes, 100 epochs, lr=0.001, \"stress-model-gcn\"\n",
    "# Total parameters:  76225\n",
    "# Performance:\n",
    "#                     Median R2\n",
    "#         Train set:   0.5444\n",
    "#          Test set:   0.5409\n",
    "\n",
    "# conv_info = get_default_conv_info(\"EdgeConv\")\n",
    "# conv_info[\"dims\"] = [64,64]\n",
    "# model = GraphUNet(num_layers=3, num_channels=64, conv_info=conv_info, mlp_dims=[128,128,128]).to(device)\n",
    "# 67 minutes, 75 epochs, lr=0.001, \"stress-model\"\n",
    "# Total parameters:  159745\n",
    "# Performance:\n",
    "#                     Median R2\n",
    "#         Train set:   0.9013\n",
    "#          Test set:   0.8743\n",
    "\n",
    "# model = JustConvNet(num_convs=4, conv_dims=[64,64], channels=64, mlp_dims = [128,128,128]).to(device)\n",
    "# 120 minutes, 200 epochs, lr=0.0001, \"stress-model-plain\"\n",
    "# Total parameters:  91457\n",
    "# Performance:\n",
    "#                     Median R2\n",
    "#         Train set:   0.439\n",
    "#          Test set:   0.4154\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "epochs = 50\n",
    "opt = optim.Adam(params=model.parameters(), lr=lr)\n",
    "lossfun = nn.MSELoss().to(device)\n",
    "# all_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    losses = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        loss = lossfun(model(data, device).reshape(-1,1), data.y.reshape(-1,1).to(device))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "        print(f\"Batch {i+1}/{len(train_loader)}: Loss = {loss.item():.6e}, Avg = {np.mean(np.array(losses)):.6e}          \",end=\"\\r\")\n",
    "        # del data\n",
    "        # torch.cuda.empty_cache() \n",
    "\n",
    "    if 1: # 0 == (epoch%5):\n",
    "        print(f\"Epoch: {epoch}/{epochs}, Loss: {np.mean(np.array(losses)):.6e}                             \")# (max {np.max(np.array(losses)):.6e}, median {np.median(np.array(losses)):.6e})                \")\n",
    "    all_losses.append(np.array(losses))\n",
    "\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        loss = lossfun(model(data, device).reshape(-1,1), data.y.reshape(-1,1).to(device))\n",
    "        losses.append(loss.item())\n",
    "        # del data\n",
    "        # torch.cuda.empty_cache() \n",
    "    if 1: # 0 == (epoch%5):\n",
    "        print(f\"   Val. Loss: {np.mean(np.array(losses)):.6e}                              \")\n",
    "    val_losses.append(np.array(losses))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(\"stress-model-plain-losses.npz\", all_losses=np.array(all_losses), val_losses=np.array(val_losses))\n",
    "# torch.save(model, \"stress-model-plain.pth\")\n",
    "# model = torch.load(\"stress-model-plain.pth\").to(device)\n",
    "\n",
    "\n",
    "#np.savez(\"stress-model-losses.npz\", all_losses=np.array(all_losses), val_losses=np.array(val_losses))\n",
    "#torch.save(model, \"stress-model.pth\")\n",
    "# model = torch.load(\"stress-model.pth\").to(device)\n",
    "\n",
    "\n",
    "np.savez(\"stress-model-gcn-losses.npz\", all_losses=np.array(all_losses), val_losses=np.array(val_losses))\n",
    "torch.save(model, \"stress-model-gcn.pth\")\n",
    "# model = torch.load(\"stress-model-gcn.pth\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_plain = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = eval_model_multiple(model, dict(tr=dataset_tr, te=dataset_te), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(\"Performance:\")\n",
    "print(\"                    Median R2\")\n",
    "print(\"        Train set:  \", np.round(np.median(vals[\"tr\"]),4))\n",
    "print(\"         Test set:  \", np.round(np.median(vals[\"te\"]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxes(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 107\n",
    "data = dataset_te[i]\n",
    "plot_comparison(model, data, device=device)\n",
    "\n",
    "i = 105\n",
    "data = dataset_te[i]\n",
    "plot_comparison(model, data, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"stress-model-plain.pth\").to(device)\n",
    "model2 = torch.load(\"stress-model-gcn.pth\").to(device)\n",
    "model3 = torch.load(\"stress-model.pth\").to(device)\n",
    "models = dict(model1=model1, model2=model2, model3=model3)\n",
    "model_names=dict(model1=\"Plain GNN (EdgeConv)\", model2=\"TAG U-Net (GCNConv)\", model3=\"TAG U-Net (EdgeConv)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2file=\"r2_data.npz\"\n",
    "if os.path.isfile(r2file):\n",
    "    r2s = np.load(r2file)\n",
    "else:\n",
    "    r2s = dict()\n",
    "    for key in models:\n",
    "        vals = eval_model_multiple(models[key], dict(tr=dataset_tr, te=dataset_te), device=device)\n",
    "        r2s[key] = vals\n",
    "    np.savez(r2file,r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_color=dict(model1=\"darkred\", model2=\"blue\", model3=\"green\")\n",
    "plt.figure(dpi=200)\n",
    "for key in models:\n",
    "    te = r2s[key][\"te\"]\n",
    "    log = True\n",
    "    bins = 20\n",
    "    plt.hist(te[te>-1], bins=bins, density=True, histtype=\"step\", lw=3., edgecolor=model_color[key], label=model_names[key])\n",
    "    #plt.hist(te[te>-1], bins=bins, density=True, alpha=0.3, , log=log, histtype=\"stepfilled\", color=model_color[key])\n",
    "plt.legend()\n",
    "plt.xlabel(\"$R^2$\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"2-D Stress Prediction Task\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(models, data, model_names, filename=None, dpi=300, size=13, device=\"cpu\"):\n",
    "    N = len(models)\n",
    "    plt.figure(figsize=(4.2*(N+1), 9.5), dpi=dpi)\n",
    "    s = size# / (1 + 7*(3000<data.x.shape[0]))\n",
    "    small_axes = []\n",
    "\n",
    "    maxval = np.max(data.y.detach().numpy())\n",
    "    for key in models:\n",
    "        pred = models[key].to(device)(data, device=device).cpu().detach().numpy()\n",
    "        maxval = max(maxval, np.max(pred))\n",
    "\n",
    "    plt.subplot(2,N+1,1)\n",
    "    plt.title(\"Ground Truth\", fontsize=17)\n",
    "    plot_data(data, data.y, size=s, color_bounds=[0,maxval])\n",
    "    \n",
    "    i = 2\n",
    "    for key in models:\n",
    "        model = models[key].to(device)\n",
    "        pred = model(data, device=device).cpu().flatten()\n",
    "\n",
    "        plt.subplot(2,N+1,i)\n",
    "        plt.title(model_names[key], fontsize=17)\n",
    "        plot_data(data, pred, size=s, color_bounds=[0,maxval])\n",
    "\n",
    "        ax = plt.subplot(2,N+1,i+4)\n",
    "        plot_model_r2(model, data, device=device)\n",
    "        plt.axis(\"scaled\")\n",
    "        small_axes.append(ax)\n",
    "        i += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.14, hspace=0)\n",
    "    for ax in small_axes:\n",
    "        pos1 = ax.get_position() # get the original position \n",
    "        pos2 = [pos1.x0 + 0.01, pos1.y0 + 0.1/N,  pos1.width * 0.9, pos1.height * 0.9] \n",
    "        ax.set_position(pos2) # set a new position\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, bbox_inches = \"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.imshow(np.flipud(dataset_te[imed].data[0].sdf.squeeze().detach().numpy()),cmap=\"seismic\", vmin=-2,vmax=2)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(r2s[\"model3\"][\"te\"])\n",
    "imed = idx[3*len(idx)//4-10]\n",
    "plot_model_comparison(models, dataset_te[imed],model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(xy, edges, node_color='black', edge_color=None, node_size = 100, \n",
    "               color_bounds = None, label = None, linewidth = 1, colorbar=True):\n",
    "    ''' \n",
    "    plot_graph: Plots a 2D graph's nodes and edges on the current axes\n",
    "    \n",
    "    Args:\n",
    "    xy - Two-column array with coordinates: [x, y]\n",
    "    edges - Array of node index pairs for each 1-directional edge\n",
    "    node_color - Color string, array, or rgb triple, defaults to 'black'\n",
    "    edge_color - Color string or rgb triple for each edge (None: no edges)\n",
    "    node_size - Size of each node, defaults to 100\n",
    "    color_bounds - [value of lowest color, value of highest color], when node_color is an array\n",
    "    label - Name of the plot for use in a legend (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - handle of node scatter plot\n",
    "    '''\n",
    "\n",
    "    x = xy[:,0]\n",
    "    y = xy[:,1]\n",
    "\n",
    "\n",
    "    if edge_color is not None:\n",
    "        edges = edges[:,edges[0,:] < edges[1,:]]\n",
    "        for edge in edges.T:\n",
    "            plt.plot([x[edge[0]],x[edge[1]]], [y[edge[0]],y[edge[1]]], c=edge_color, zorder=0, linewidth=linewidth)\n",
    "    \n",
    "    if label is not None:\n",
    "        title_height = 0.88\n",
    "        fontsize = 12\n",
    "        plt.title(label, fontsize=fontsize, y=title_height)\n",
    "\n",
    "    if type(node_color) == str:\n",
    "        handle = plt.scatter(x,y, s=node_size, c=node_color, zorder=1, label=label, cmap='jet')\n",
    "    else:\n",
    "        if color_bounds is None:\n",
    "            tick_min = np.round(np.min(node_color),3)\n",
    "            tick_max = np.round(np.max(node_color),3)\n",
    "        elif len(color_bounds) == 1:\n",
    "            tick_min = color_bounds[0]\n",
    "            tick_max = np.round(np.max(node_color),3)\n",
    "        else:\n",
    "            tick_min = color_bounds[0]\n",
    "            tick_max = color_bounds[1]\n",
    "        cb = dict(vmin=tick_min, vmax=tick_max)\n",
    "        tick_min = cb[\"vmin\"]\n",
    "        tick_max = cb[\"vmax\"]\n",
    "        tick_med = np.round((tick_min + tick_max)/2,3)\n",
    "        handle = plt.scatter(x,y, s=node_size, c=node_color, zorder=1, label=label, cmap='jet', **cb)\n",
    "\n",
    "        if colorbar:\n",
    "            cbar_shrink = 0.9\n",
    "            cbar_pad = -0.1\n",
    "            bar = plt.colorbar(shrink=cbar_shrink, location='bottom', pad=cbar_pad, ticks=[tick_min, tick_med, tick_max])\n",
    "            bar.ax.set_xticklabels([tick_min, tick_med, tick_max])\n",
    "\n",
    "    plt.axis(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    return handle\n",
    "\n",
    "def plot_data(data, colors=\"black\", show_edges=False, color_bounds=None, label = None, size=30, width=.4, colorbar=True):\n",
    "    xy = data.x[:,:2].detach().numpy()\n",
    "    edges = data.edge_index.detach().numpy()\n",
    "    node_color = colors.detach().numpy() if type(colors) == torch.Tensor else colors\n",
    "    edge_color = \"black\" if show_edges else None\n",
    "    handle = plot_graph(xy, edges, node_color=node_color, edge_color=edge_color, node_size=size, \n",
    "                        color_bounds=color_bounds, label=label, linewidth=width, colorbar=colorbar)\n",
    "    return handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.data[0]\n",
    "plt.figure(dpi=300)\n",
    "plot_data(data, show_edges=True, size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].data[1]\n",
    "plt.figure(dpi=300)\n",
    "plot_data(data, show_edges=True, size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-360-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
